# RagaSense-Data Project Structure

## ğŸ“ Directory Organization

```
RagaSense-Data/
â”œâ”€â”€ ğŸ“„ README.md                    # Main project documentation
â”œâ”€â”€ ğŸ“„ requirements.txt             # Python dependencies
â”œâ”€â”€ ğŸ“„ pyproject.toml              # Project configuration
â”œâ”€â”€ ğŸ“„ .gitignore                  # Git ignore rules
â”œâ”€â”€ ğŸ“„ PROJECT_STRUCTURE.md        # This file
â”‚
â”œâ”€â”€ ğŸ“ data/                       # Main dataset directory
â”‚   â”œâ”€â”€ ğŸ“ raw/                   # Original, unprocessed data
â”‚   â”‚   â”œâ”€â”€ ramanarunachalam/     # Ramanarunachalam repository
â”‚   â”‚   â”œâ”€â”€ saraga_datasets/      # Saraga 1.5 datasets
â”‚   â”‚   â”œâ”€â”€ saraga_carnatic_melody_synth/ # Melody synth data
â”‚   â”‚   â””â”€â”€ carnatic_varnam/      # Varnam dataset
â”‚   â”œâ”€â”€ ğŸ“ processed/             # Cleaned and processed data
â”‚   â”‚   â”œâ”€â”€ unified_ragas.json    # Main raga database
â”‚   â”‚   â”œâ”€â”€ unified_artists.json  # Artist database
â”‚   â”‚   â”œâ”€â”€ unified_tracks.json   # Track database
â”‚   â”‚   â””â”€â”€ cross_tradition_mappings.json
â”‚   â”œâ”€â”€ ğŸ“ ml_ready/              # ML training datasets
â”‚   â””â”€â”€ ğŸ“ exports/               # Community export formats
â”‚
â”œâ”€â”€ ğŸ“ scripts/                    # Processing and analysis scripts
â”‚   â”œâ”€â”€ ğŸ“ data_processing/       # Data processing pipelines
â”‚   â”‚   â”œâ”€â”€ process_saraga_datasets.py
â”‚   â”‚   â”œâ”€â”€ simple_saraga_processor.py
â”‚   â”‚   â”œâ”€â”€ comprehensive_data_processor.py
â”‚   â”‚   â””â”€â”€ extract_audio_features.py
â”‚   â”œâ”€â”€ ğŸ“ analysis/              # Data analysis tools
â”‚   â”‚   â”œâ”€â”€ analyze_real_data.py
â”‚   â”‚   â”œâ”€â”€ analyze_saraga_datasets.py
â”‚   â”‚   â””â”€â”€ comprehensive_data_analysis.py
â”‚   â”œâ”€â”€ ğŸ“ exploration/           # Data exploration tools
â”‚   â”‚   â”œâ”€â”€ explore_ragasense_data.py
â”‚   â”‚   â””â”€â”€ web_explorer.py
â”‚   â”œâ”€â”€ ğŸ“ integration/           # Dataset integration
â”‚   â”‚   â”œâ”€â”€ integrate_all_datasets.py
â”‚   â”‚   â”œâ”€â”€ create_unified_dataset.py
â”‚   â”‚   â””â”€â”€ unified_dataset_integration.py
â”‚   â””â”€â”€ ğŸ“ utilities/             # Utility scripts
â”‚       â””â”€â”€ organize_workspace.py
â”‚
â”œâ”€â”€ ğŸ“ ml_models/                  # Machine learning models
â”‚   â”œâ”€â”€ ğŸ“ training/              # Training scripts
â”‚   â”‚   â””â”€â”€ gpu_optimized_trainer.py
â”‚   â”œâ”€â”€ ğŸ“ models/                # Trained models
â”‚   â”œâ”€â”€ ğŸ“ inference/             # Inference scripts
â”‚   â”œâ”€â”€ ğŸ“ experiments/           # ML experiments
â”‚   â”œâ”€â”€ raga_detection_system.py  # Core ML system
â”‚   â”œâ”€â”€ raga_detection_api.py     # API server
â”‚   â”œâ”€â”€ train_raga_model.py       # Training script
â”‚   â”œâ”€â”€ demo_raga_detection.py    # Demo script
â”‚   â”œâ”€â”€ requirements.txt          # ML dependencies
â”‚   â””â”€â”€ README.md                 # ML documentation
â”‚
â”œâ”€â”€ ğŸ“ tools/                      # Development tools
â”‚   â”œâ”€â”€ ğŸ“ analysis/              # Analysis tools
â”‚   â”œâ”€â”€ ğŸ“ audio/                 # Audio processing tools
â”‚   â”œâ”€â”€ ğŸ“ conversion/            # Format conversion tools
â”‚   â”œâ”€â”€ ğŸ“ data_processing/       # Data processing tools
â”‚   â”œâ”€â”€ ğŸ“ exploration/           # Exploration tools
â”‚   â”œâ”€â”€ ğŸ“ export/                # Export tools
â”‚   â”œâ”€â”€ ğŸ“ graph-db/              # Graph database tools
â”‚   â”œâ”€â”€ ğŸ“ ingestion/             # Data ingestion tools
â”‚   â”œâ”€â”€ ğŸ“ ml/                    # ML tools
â”‚   â”œâ”€â”€ ğŸ“ utils/                 # Utility tools
â”‚   â”œâ”€â”€ ğŸ“ validation/            # Validation tools
â”‚   â””â”€â”€ ğŸ“ web/                   # Web tools
â”‚
â”œâ”€â”€ ğŸ“ docs/                       # Documentation
â”‚   â”œâ”€â”€ ğŸ“ overview/              # Project overview
â”‚   â”œâ”€â”€ ğŸ“ processing/            # Processing documentation
â”‚   â”œâ”€â”€ ğŸ“ api-reference/         # API documentation
â”‚   â”œâ”€â”€ ğŸ“ contribution-guide/    # Contribution guidelines
â”‚   â”œâ”€â”€ ğŸ“ dataset-guide/         # Dataset usage guide
â”‚   â”œâ”€â”€ ğŸ“ data-sources/          # Data source documentation
â”‚   â”œâ”€â”€ ğŸ“ ml_models/             # ML model documentation
â”‚   â””â”€â”€ ğŸ“ website/               # Website documentation
â”‚
â”œâ”€â”€ ğŸ“ schemas/                    # Database schemas
â”‚   â”œâ”€â”€ graph-schema.cypher       # Neo4j graph schema
â”‚   â”œâ”€â”€ neo4j_schema.cypher       # Neo4j schema
â”‚   â”œâ”€â”€ mapping-schema.json       # Mapping schema
â”‚   â””â”€â”€ metadata-schema.json      # Metadata schema
â”‚
â”œâ”€â”€ ğŸ“ examples/                   # Usage examples
â”‚   â”œâ”€â”€ basic-queries/            # Basic query examples
â”‚   â”œâ”€â”€ research-examples/        # Research examples
â”‚   â””â”€â”€ sample_data/              # Sample data files
â”‚
â”œâ”€â”€ ğŸ“ tests/                      # Test files
â”‚
â”œâ”€â”€ ğŸ“ config/                     # Configuration files
â”‚   â”œâ”€â”€ project_config.yaml       # Project configuration
â”‚   â””â”€â”€ wandb_config.yaml         # Weights & Biases config
â”‚
â”œâ”€â”€ ğŸ“ governance/                 # Data governance
â”‚   â”œâ”€â”€ data_policy.md            # Data policy
â”‚   â”œâ”€â”€ quality_standards.md      # Quality standards
â”‚   â”œâ”€â”€ access_control.md         # Access control
â”‚   â””â”€â”€ data_lineage.json         # Data lineage
â”‚
â”œâ”€â”€ ğŸ“ website/                    # Web interface
â”‚   â”œâ”€â”€ ğŸ“ src/                   # Source code
â”‚   â”œâ”€â”€ ğŸ“ dist/                  # Built website
â”‚   â”œâ”€â”€ package.json              # Node dependencies
â”‚   â”œâ”€â”€ astro.config.mjs          # Astro configuration
â”‚   â””â”€â”€ vercel.json               # Vercel deployment config
â”‚
â”œâ”€â”€ ğŸ“ logs/                       # Log files
â”‚   â”œâ”€â”€ ğŸ“ analysis/              # Analysis logs
â”‚   â”œâ”€â”€ ğŸ“ data_processing/       # Processing logs
â”‚   â”œâ”€â”€ ğŸ“ exploration/           # Exploration logs
â”‚   â””â”€â”€ ğŸ“ integration/           # Integration logs
â”‚
â””â”€â”€ ğŸ“ archive/                    # Archived files
    â”œâ”€â”€ ğŸ“ root_files/            # Archived root files
    â”œâ”€â”€ ğŸ“ old_scripts/           # Archived scripts
    â”œâ”€â”€ ğŸ“ old_docs/              # Archived documentation
    â”œâ”€â”€ ğŸ“ data_versions/         # Archived data versions
    â”œâ”€â”€ ğŸ“ analysis_results/      # Archived analysis results
    â”œâ”€â”€ ğŸ“ downloads/             # Archived downloads
    â”œâ”€â”€ ğŸ“ duplicates/            # Duplicate files
    â””â”€â”€ ğŸ“ config/                # Archived configuration
```

## ğŸ¯ Best Practices Applied

### 1. **Clear Separation of Concerns**
- **Data**: Raw, processed, ML-ready, and export formats
- **Scripts**: Organized by function (processing, analysis, exploration, integration)
- **Tools**: Development and utility tools
- **Documentation**: Comprehensive and well-organized

### 2. **Scalable Structure**
- **Modular design**: Easy to add new components
- **Clear naming**: Descriptive directory and file names
- **Logical grouping**: Related files grouped together

### 3. **Development Best Practices**
- **Configuration management**: Centralized config files
- **Testing**: Dedicated tests directory
- **Documentation**: Comprehensive docs structure
- **Version control**: Proper .gitignore and project config

### 4. **Data Management**
- **Raw data preservation**: Original data never modified
- **Processing pipeline**: Clear data flow from raw to ML-ready
- **Export formats**: Multiple formats for different use cases
- **Archive system**: Old versions preserved but organized

### 5. **Community Ready**
- **Clear documentation**: README, guides, and examples
- **Easy installation**: requirements.txt and pyproject.toml
- **Web interface**: Live website for data exploration
- **API access**: RESTful API for programmatic access

## ğŸš€ Usage

### Quick Start
```bash
# Install dependencies
pip install -r requirements.txt

# Explore data
python3 scripts/exploration/explore_ragasense_data.py

# Process data
python3 scripts/data_processing/simple_saraga_processor.py

# Train ML model
python3 ml_models/training/gpu_optimized_trainer.py
```

### Web Interface
Visit: https://ragasense-data-j26pv45x8-radhi1991s-projects.vercel.app

This structure follows industry best practices for data science and machine learning projects, making it easy to navigate, maintain, and contribute to.

